# Design Decisions - Объяснение принятых решений

Этот документ содержит подробные объяснения архитектурных и технических решений, принятых при разработке проекта. См. также краткую версию в основном [README.md](README.md).

## 1. Clean Architecture - Разделение на слои

**Решение**: Проект разделен на 4 основных слоя:
- `domain/` - доменные модели (Price)
- `application/` - бизнес-логика (Use Cases)
- `infrastructure/` - внешние зависимости (БД, API клиенты, Celery)
- `presentation/` - API endpoints и схемы

**Почему**: 

В предыдущих проектах сталкивался с проблемой, когда бизнес-логика была перемешана с деталями реализации БД. Например, если нужно было заменить PostgreSQL на MongoDB, приходилось переписывать половину кода. 

С Clean Architecture:
- Бизнес-логика (Use Cases) не знает о том, что данные хранятся в PostgreSQL
- Можно легко заменить БД - достаточно переписать только `PriceRepository`
- Можно добавить кэш (Redis) - просто обернуть репозиторий, use cases не изменятся
- Тесты проще - мокаем только репозиторий, а не всю БД

**Альтернативы, которые рассматривал**:
- Простая структура с моделями Django/FastAPI - но тогда бизнес-логика смешивается с ORM
- Монолитная структура - но сложнее тестировать и масштабировать

## 2. Async/Await для работы с БД и внешним API

**Решение**: Использован `asyncpg` для PostgreSQL и `aiohttp` для HTTP-запросов к Deribit API.

**Почему**:

Celery задачи могут делать несколько запросов к API одновременно (BTC и ETH). С синхронным подходом:
- Запрос BTC: ~200ms
- Запрос ETH: ~200ms
- Итого: ~400ms

С асинхронным:
- Оба запроса параллельно: ~200ms
- Экономия времени в 2 раза

При росте количества тикеров (если добавить LTC, XRP и т.д.) выигрыш будет еще больше. Плюс asyncpg дает лучшую производительность при множественных запросах к БД.

**Альтернативы**:
- `psycopg2` (синхронный) - проще, но медленнее
- `requests` вместо `aiohttp` - но тогда нельзя делать параллельные запросы

## 3. Repository Pattern для доступа к данным

**Решение**: Доступ к данным инкапсулирован в `PriceRepository`. Use Cases работают только с репозиторием, не зная деталей БД.

**Почему**:

Без репозитория пришлось бы тащить `asyncpg.Pool` через все слои:
```python
# Плохо - детали БД в use case
class GetAllPricesUseCase:
    def __init__(self, pool: asyncpg.Pool):
        self.pool = pool
```

С репозиторием:
```python
# Хорошо - абстракция
class GetAllPricesUseCase:
    def __init__(self, repository: PriceRepository):
        self.repository = repository
```

**Преимущества**:
- Если понадобится добавить Redis-кэш - просто обернуть репозиторий:
  ```python
  class CachedPriceRepository:
      def __init__(self, repo: PriceRepository, cache: Redis):
          self.repo = repo
          self.cache = cache
  ```
- Use cases не изменятся
- Легко тестировать - мокаем только репозиторий

## 4. Use Cases как отдельные классы

**Решение**: Каждое действие (получить все цены, последнюю цену, цену по дате) вынесено в отдельный класс Use Case.

**Почему**:

Хотя use cases простые (просто вызывают репозиторий), отдельные классы дают:
- **Простое тестирование**: мокаем только репозиторий, не нужно поднимать БД
- **Расширяемость**: если появятся дополнительные проверки (валидация тикера, лимиты на количество записей), их легко добавить в один класс
- **Читаемость**: из названия класса сразу понятно, что он делает

**Альтернативы**:
- Один большой класс `PriceUseCase` с методами - но тогда сложнее тестировать отдельные сценарии
- Функции вместо классов - но тогда сложнее добавлять зависимости и расширять функциональность

## 5. Celery для периодических задач

**Решение**: Использован Celery с периодическими задачами (beat) для получения цен каждую минуту.

**Почему**:

**Альтернативы, которые рассматривал**:

1. **Простой `asyncio.sleep` в отдельном процессе**:
   ```python
   # Плохо
   while True:
       await fetch_prices()
       await asyncio.sleep(60)
   ```
   Проблемы:
   - Нет retry при ошибках
   - Нет масштабирования (нельзя запустить несколько воркеров)
   - Нет мониторинга задач
   - Если процесс упадет - задачи остановятся

2. **Cron задача**:
   - Не подходит для async кода
   - Сложнее обрабатывать ошибки
   - Нет очереди задач

3. **Celery** (выбран):
   - ✅ Retry при ошибках из коробки
   - ✅ Можно масштабировать - запустить несколько воркеров
   - ✅ Мониторинг через Flower или админку
   - ✅ Очередь задач - если одна задача долго выполняется, следующая подождет
   - ✅ Можно добавить приоритеты задач

## 6. Dependency Injection через FastAPI

**Решение**: Подключение к БД управляется через `lifespan` events и передается через `app.state`. Репозиторий создается через dependency injection.

**Почему**:

**Проблема с глобальными переменными**:
```python
# Плохо
_db = Database()

@router.get("/prices")
async def get_prices():
    repo = PriceRepository(_db)  # Использует глобальную переменную
```

Проблемы:
- Сложно тестировать - нужно мокать глобальную переменную
- Нельзя использовать разные БД в разных тестах
- Проблемы с многопоточностью

**Решение с DI**:
```python
# Хорошо
async def get_repository(request: Request) -> PriceRepository:
    db = request.app.state.db
    return PriceRepository(db)

@router.get("/prices")
async def get_prices(repository: PriceRepository = Depends(get_repository)):
    # FastAPI автоматически создает репозиторий
```

Преимущества:
- Легко тестировать - можно подменить `get_repository` на мок
- Можно использовать разные БД в разных тестах
- Нет глобальных переменных

## 7. Отсутствие миграций (Alembic)

**Решение**: Таблица создается автоматически при первом запуске через `create_table_if_not_exists()`.

**Почему**:

Для production нужен Alembic, но для тестового задания это избыточно:
- Схема простая (одна таблица) и не меняется
- Нет необходимости в откате миграций
- Упрощает развертывание - не нужно запускать миграции отдельно

**Когда нужен Alembic**:
- Если схема будет меняться (добавление колонок, индексов)
- Если нужен откат миграций
- Если несколько окружений (dev, staging, production) с разными версиями схемы

## 8. DECIMAL для цены в БД, float в коде

**Решение**: В PostgreSQL цена хранится как `DECIMAL(20, 8)`, в коде используется `float`.

**Почему**:

**Проблема с float в БД**:
```python
# Плохо - потеря точности
price = 50000.12345678
# В БД может сохраниться как 50000.12345677
```

**DECIMAL в БД**:
- Гарантирует точность для финансовых расчетов
- 20 цифр всего, 8 после запятой - достаточно для криптовалют

**float в коде**:
- Проще работать (не нужно конвертировать Decimal)
- Для этого проекта точности float достаточно
- Если понадобится большая точность - легко перейти на `Decimal` из стандартной библиотеки

## 9. aiohttp для HTTP-клиента

**Решение**: Использован `aiohttp` для асинхронных HTTP-запросов к Deribit API.

**Почему**:

**Требование ТЗ**: "Применить aiohttp при написании клиента" (необязательное требование).

**Преимущества aiohttp**:
- Асинхронный - можно делать параллельные запросы
- Поддержка connection pooling - переиспользует соединения
- Поддержка таймаутов из коробки
- Хорошая документация

**Альтернативы**:
- `requests` - синхронный, не подходит для async кода
- `httpx` - тоже async, но aiohttp более зрелый и стабильный

## 10. Структура проекта и именование

**Решение**: 
- Папки: `domain/`, `application/`, `infrastructure/`, `presentation/`
- Имена классов: `PriceRepository`, `GetAllPricesUseCase`, `DeribitClient`
- Имена методов: `get_all_by_ticker`, `get_last_by_ticker`

**Почему**:

**Именование**:
- Избегал общих имен типа `result`, `data`, `handler`
- Использовал конкретные имена: `index_price`, `price_responses`, `api_response`
- Имена отражают бизнес-контекст, а не технические детали

**Структура**:
- Следует принципам Clean Architecture
- Легко найти нужный код
- Легко добавлять новые фичи

## 11. Обработка ошибок

**Решение**: Конкретные исключения вместо `except Exception`.

**Почему**:

```python
# Плохо
except Exception:
    return None
```

Проблемы:
- Ловит все ошибки, включая системные (KeyboardInterrupt, SystemExit)
- Скрывает реальные проблемы
- Сложно отлаживать

```python
# Хорошо
except (aiohttp.ClientError, asyncio.TimeoutError):
    return None
```

Преимущества:
- Ловим только ожидаемые ошибки
- Системные ошибки не скрываются
- Легче отлаживать

## 12. Docker Compose с 4 контейнерами

**Решение**: 4 контейнера: PostgreSQL, Redis, API (FastAPI), Celery worker.

**Почему**:

**Требование ТЗ**: "Развернуть приложение в двух контейнерах для приложения и базы данных" (необязательное).

Я сделал 4 контейнера, потому что:
- Celery нужен отдельный процесс (нельзя запустить в том же процессе, что и API)
- Redis нужен для Celery (broker и backend)
- Это стандартная практика для production-ready приложений

**Альтернатива** (минимальная):
- 2 контейнера: API+Celery в одном, PostgreSQL
- Но тогда нельзя масштабировать API и Celery отдельно

## Итог

Все решения приняты с учетом:
- **Практичности** - что будет работать в реальном проекте
- **Расширяемости** - легко добавить новые фичи
- **Тестируемости** - легко писать тесты
- **Читаемости** - код понятен другим разработчикам
